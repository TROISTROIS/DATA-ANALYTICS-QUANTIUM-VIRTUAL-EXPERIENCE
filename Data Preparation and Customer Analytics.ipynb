{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88010514",
   "metadata": {},
   "source": [
    "# GOAL : \n",
    "## FIND THE TYPE OF CUSTOMERS WHO PURCHASE CHIPS AND THEIR PURCHASING BEHAVIOUR WITHIN THE REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e5ae53",
   "metadata": {},
   "source": [
    "# PART ONE\n",
    "\n",
    "## Examine Transaction Data\n",
    "1. Look for inconsistencies, missing data across the dataset, outliers, correctly identified category items, numeric data across all tables.\n",
    "2. In case of identified anomalies, make necessary changes to the dataset and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f852b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import chardet\n",
    "from datetime import datetime, timedelta\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc95f5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ascii\n"
     ]
    }
   ],
   "source": [
    "# encoding used in the file\n",
    "with open (\"QVI_transaction_data.csv\", mode='rb') as file:\n",
    "    raw_bytes = file.read(5)\n",
    "    detected_encoding = chardet.detect(raw_bytes)['encoding']\n",
    "    print(detected_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "902aa182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DATE', 'STORE_NBR', 'LYLTY_CARD_NBR', 'TXN_ID', 'PROD_NBR', 'PROD_NAME', 'PROD_QTY', 'TOT_SALES'], ['43390', '1', '1000', '1', '5', 'Natural Chip        Compny SeaSalt175g', '2', '6'], ['43599', '1', '1307', '348', '66', 'CCs Nacho Cheese    175g', '3', '6.3'], ['43605', '1', '1343', '383', '61', 'Smiths Crinkle Cut  Chips Chicken 170g', '2', '2.9'], ['43329', '2', '2373', '974', '69', 'Smiths Chip Thinly  S/Cream&Onion 175g', '5', '15'], ['43330', '2', '2426', '1038', '108', 'Kettle Tortilla ChpsHny&Jlpno Chili 150g', '3', '13.8'], ['43604', '4', '4074', '2982', '57', 'Old El Paso Salsa   Dip Tomato Mild 300g', '1', '5.1'], ['43601', '4', '4149', '3333', '16', 'Smiths Crinkle Chips Salt & Vinegar 330g', '1', '5.7'], ['43601', '4', '4196', '3539', '24', 'Grain Waves         Sweet Chilli 210g', '1', '3.6'], ['43332', '5', '5026', '4525', '42', 'Doritos Corn Chip Mexican Jalapeno 150g', '1', '3.9']]\n"
     ]
    }
   ],
   "source": [
    "# convert from ascii to utf-8\n",
    "with open(\"QVI_transaction_data.csv\", encoding='utf-8') as file:\n",
    "    rows = list(csv.reader(file))\n",
    "    header = rows[0]\n",
    "    print(rows[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a466f449",
   "metadata": {},
   "source": [
    "# INSIGHTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1a7aca",
   "metadata": {},
   "source": [
    "1. **ASCII** encoding is used in the csv file.\n",
    "2. The Date Column doers not look like a date.\n",
    "3. Numbers are represented as strings. \n",
    "4. Format headers to have the correct spelling and start with uppercase only.\n",
    "5. Separate quantity from product name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b43695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the dataset\n",
    "def explore_dataset(dataset,start,end,rows_columns=False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print(\"\\n\")\n",
    "    if rows_columns:\n",
    "        print(\"There are {} rows\".format(len(dataset)))\n",
    "        print(\"There are {} columns\".format(len(dataset[0])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "509dbfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DATE', 'STORE_NBR', 'LYLTY_CARD_NBR', 'TXN_ID', 'PROD_NBR', 'PROD_NAME', 'PROD_QTY', 'TOT_SALES']\n",
      "\n",
      "\n",
      "['43390', '1', '1000', '1', '5', 'Natural Chip        Compny SeaSalt175g', '2', '6']\n",
      "\n",
      "\n",
      "['43599', '1', '1307', '348', '66', 'CCs Nacho Cheese    175g', '3', '6.3']\n",
      "\n",
      "\n",
      "['43605', '1', '1343', '383', '61', 'Smiths Crinkle Cut  Chips Chicken 170g', '2', '2.9']\n",
      "\n",
      "\n",
      "['43329', '2', '2373', '974', '69', 'Smiths Chip Thinly  S/Cream&Onion 175g', '5', '15']\n",
      "\n",
      "\n",
      "['43330', '2', '2426', '1038', '108', 'Kettle Tortilla ChpsHny&Jlpno Chili 150g', '3', '13.8']\n",
      "\n",
      "\n",
      "['43604', '4', '4074', '2982', '57', 'Old El Paso Salsa   Dip Tomato Mild 300g', '1', '5.1']\n",
      "\n",
      "\n",
      "['43601', '4', '4149', '3333', '16', 'Smiths Crinkle Chips Salt & Vinegar 330g', '1', '5.7']\n",
      "\n",
      "\n",
      "['43601', '4', '4196', '3539', '24', 'Grain Waves         Sweet Chilli 210g', '1', '3.6']\n",
      "\n",
      "\n",
      "['43332', '5', '5026', '4525', '42', 'Doritos Corn Chip Mexican Jalapeno 150g', '1', '3.9']\n",
      "\n",
      "\n",
      "There are 264837 rows\n",
      "There are 8 columns\n"
     ]
    }
   ],
   "source": [
    "explore_dataset(rows,0,10,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dd8ccd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DATE', 'STORE_NBR', 'LYLTY_CARD_NBR', 'TXN_ID', 'PROD_NBR', 'PROD_NAME', 'PROD_QTY', 'TOT_SALES']\n",
      "\n",
      "\n",
      "['43390', '1', '1000', '1', '5', 'Natural Chip        Compny SeaSalt175g', '2', '6']\n",
      "\n",
      "\n",
      "['43599', '1', '1307', '348', '66', 'CCs Nacho Cheese    175g', '3', '6.3']\n",
      "\n",
      "\n",
      "['43605', '1', '1343', '383', '61', 'Smiths Crinkle Cut  Chips Chicken 170g', '2', '2.9']\n",
      "\n",
      "\n",
      "['43329', '2', '2373', '974', '69', 'Smiths Chip Thinly  S/Cream&Onion 175g', '5', '15']\n",
      "\n",
      "\n",
      "There are 264837 rows\n",
      "There are 8 columns\n"
     ]
    }
   ],
   "source": [
    "# check if there are empty sublists in our list\n",
    "empty_rows =  [sublist for sublist in rows if sublist]\n",
    "explore_dataset(empty_rows,0,5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9957ac40-23b2-4667-9e41-ad33b98f12f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['43374', '107', '107024', '108462', '45', 'Smiths Thinly Cut   Roast Chicken 175g', '2', '6']]\n",
      "There are 1 duplicate entries\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates based on key columns\n",
    "duplicate_entries = []\n",
    "seen = set()\n",
    "\n",
    "for row in rows:\n",
    "#     use a tuple as a key\n",
    "    key = tuple(row)\n",
    "    if key in seen:\n",
    "        duplicate_entries.append(row)\n",
    "    else:\n",
    "        seen.add(key)\n",
    "# duplicate entries\n",
    "duplicates = []\n",
    "for duplicate in duplicate_entries:\n",
    "    duplicates.append(duplicate)\n",
    "    print(duplicates)\n",
    "print(\"There are {} duplicate entries\".format(len(duplicates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a332f5b",
   "metadata": {},
   "source": [
    "1 duplicate entry to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f10cea29-0e41-49d4-ab9d-ec60f20c717d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DATE': 0, 'STORE_NBR': 1, 'LYLTY_CARD_NBR': 2, 'TXN_ID': 3, 'PROD_NBR': 4, 'PROD_NAME': 5, 'PROD_QTY': 6, 'TOT_SALES': 7}\n"
     ]
    }
   ],
   "source": [
    "# get the index of every column\n",
    "col_index = {}\n",
    "for i in range(len(header)):\n",
    "    col_index[header[i]] = i\n",
    "print(col_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9803985-316d-4dec-a8e0-5868c782a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert excel date to python datetime object\n",
    "def excel_serial_date_to_datetime(serial_date):\n",
    "    base_date = datetime(1899, 12, 31)\n",
    "    delta = timedelta(days=float(serial_date))\n",
    "    resulting_date = base_date + delta\n",
    "    return resulting_date\n",
    "\n",
    "def serialdate_to_datetime(rows, idx):\n",
    "    for i, row in enumerate(rows):\n",
    "        if i == 0:\n",
    "            continue  # Skip header if present\n",
    "        serial_date = row[idx]\n",
    "        date = excel_serial_date_to_datetime(serial_date)\n",
    "        row[idx] = date\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7dff3605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DATE', 'STORE_NBR', 'LYLTY_CARD_NBR', 'TXN_ID', 'PROD_NBR', 'PROD_NAME', 'PROD_QTY', 'TOT_SALES'], [datetime.datetime(2018, 10, 18, 0, 0), '1', '1000', '1', '5', 'Natural Chip        Compny SeaSalt175g', '2', '6'], [datetime.datetime(2019, 5, 15, 0, 0), '1', '1307', '348', '66', 'CCs Nacho Cheese    175g', '3', '6.3'], [datetime.datetime(2019, 5, 21, 0, 0), '1', '1343', '383', '61', 'Smiths Crinkle Cut  Chips Chicken 170g', '2', '2.9'], [datetime.datetime(2018, 8, 18, 0, 0), '2', '2373', '974', '69', 'Smiths Chip Thinly  S/Cream&Onion 175g', '5', '15']]\n"
     ]
    }
   ],
   "source": [
    "rows = serialdate_to_datetime(rows, 0)\n",
    "print(rows[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb3496",
   "metadata": {},
   "source": [
    "I will write to the csv file later, to keep permanent changes of the date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcfa14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the data types match\n",
    "def check_datatypes(rows,header):    \n",
    "    # Initialize a dictionary to store the data types for each column\n",
    "    column_data_types = {col: None for col in header}\n",
    "\n",
    "    # Iterate over each row of the CSV file\n",
    "    for row in rows:\n",
    "        # Iterate over each column in the row\n",
    "        for i, col_value in enumerate(row):\n",
    "            # Check if the data type for the column has been set yet\n",
    "            if not column_data_types[header[i]]:\n",
    "                # If not, set the data type to the type of the current value\n",
    "                column_data_types[header[i]] = type(col_value)\n",
    "            else:\n",
    "                # If it has been set, check if the current value has a different data type\n",
    "                if column_data_types[header[i]] != type(col_value):\n",
    "                    # If it does, set the data type to a generic \"object\" type\n",
    "                    column_data_types[header[i]] = object\n",
    "\n",
    "    # Print the data types for each column\n",
    "    for col, data_type in column_data_types.items():\n",
    "        print(f\"{col}: {data_type.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4fccf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE: object\n",
      "STORE_NBR: str\n",
      "LYLTY_CARD_NBR: str\n",
      "TXN_ID: str\n",
      "PROD_NBR: str\n",
      "PROD_NAME: str\n",
      "PROD_QTY: str\n",
      "TOT_SALES: str\n"
     ]
    }
   ],
   "source": [
    "check_datatypes(rows,header)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0e6873",
   "metadata": {},
   "source": [
    "Columns that should be integers are represented as strings:\n",
    "1. Store Number\n",
    "2. Loyalty Card Number\n",
    "3. Prod Number \n",
    "\n",
    "The Date Column will also be converted to a datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "162915be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change Product Name column to just the product name and create another column for Quantity in grams.\n",
    "# PROD_NAME = []\n",
    "# PROD_QUANTITY = []\n",
    "\n",
    "# for row in rows:\n",
    "#     products = row[5]\n",
    "#     for product in products:\n",
    "# #     split the string into words\n",
    "#         split_product = product.rsplit(' ',1)\n",
    "#         PROD_NAME.append(split_product[0])\n",
    "#         PROD_QUANTITY.append(split_product[1])\n",
    "# for i in range(len(PROD_NAME)):\n",
    "#     print(f\"Product:{PROD_NAME[i]}, Quantity:{PROD_QUANTITY[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf72a4",
   "metadata": {},
   "source": [
    "We have created a new list of two separate columns that will be put in the csv file when writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6412d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to a new csv file\n",
    "with open('transaction1.csv', 'w',newline='', encoding='utf-8') as newfile:\n",
    "    writer = csv.writer(newfile)\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3377f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DATE', 'STORE_NBR', 'LYLTY_CARD_NBR', 'TXN_ID', 'PROD_NBR', 'PROD_NAME', 'PROD_QTY', 'TOT_SALES'], ['2018-10-18 00:00:00', '1', '1000', '1', '5', 'Natural Chip        Compny SeaSalt175g', '2', '6'], ['2019-05-15 00:00:00', '1', '1307', '348', '66', 'CCs Nacho Cheese    175g', '3', '6.3'], ['2019-05-21 00:00:00', '1', '1343', '383', '61', 'Smiths Crinkle Cut  Chips Chicken 170g', '2', '2.9'], ['2018-08-18 00:00:00', '2', '2373', '974', '69', 'Smiths Chip Thinly  S/Cream&Onion 175g', '5', '15'], ['2018-08-19 00:00:00', '2', '2426', '1038', '108', 'Kettle Tortilla ChpsHny&Jlpno Chili 150g', '3', '13.8'], ['2019-05-20 00:00:00', '4', '4074', '2982', '57', 'Old El Paso Salsa   Dip Tomato Mild 300g', '1', '5.1'], ['2019-05-17 00:00:00', '4', '4149', '3333', '16', 'Smiths Crinkle Chips Salt & Vinegar 330g', '1', '5.7'], ['2019-05-17 00:00:00', '4', '4196', '3539', '24', 'Grain Waves         Sweet Chilli 210g', '1', '3.6'], ['2018-08-21 00:00:00', '5', '5026', '4525', '42', 'Doritos Corn Chip Mexican Jalapeno 150g', '1', '3.9']]\n"
     ]
    }
   ],
   "source": [
    "# convert from ascii to utf-8\n",
    "with open(\"transaction1.csv\", encoding='utf-8') as file:\n",
    "    rows = list(csv.reader(file))\n",
    "    header = rows[0]\n",
    "    print(rows[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a73f4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format product name substring\n",
    "conn = psycopg2.connect(\"dbname=postgres user=postgres password=POSTGRES33\")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "CREATE DATABASE transaction_db\n",
    "\"\"\")\n",
    "conn.autocommit = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b27f95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to transaction_db database\n",
    "conn=psycopg2.connect(\"dbname=transaction_db user=postgres password='POSTGRES33'\")\n",
    "conn.autocommit = True\n",
    "cur=conn.cursor()\n",
    "cur.execute(\"CREATE SCHEMA store\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2636aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data from csv into table\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS store.transaction_tb (\n",
    "DATE text,\n",
    "STORE_NBR text,\n",
    "LYLTY_CARD_NBR text,\n",
    "TXN_ID text,\n",
    "PROD_NBR text,\n",
    "PROD_NAME text,\n",
    "PROD_QTY text,\n",
    "TOT_SALES text);\"\"\")        \n",
    "with open(\"transaction1.csv\",\"r\") as file:\n",
    "    cur.copy_expert(\"COPY store.transaction_tb FROM STDIN WITH CSV HEADER;\",file)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2ad17fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pg_catalog',)\n",
      "('information_schema',)\n",
      "('store',)\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\n",
    "\"\"\"\n",
    "SELECT schemaname\n",
    "FROM pg_catalog.pg_tables\n",
    "GROUP BY schemaname\n",
    "\"\"\")\n",
    "schemas = cur.fetchall()\n",
    "for schema in schemas:\n",
    "    print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58e8abef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "('transaction_tb',)\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\n",
    "\"\"\"\n",
    "SELECT tablename \n",
    "FROM pg_catalog.pg_tables\n",
    "WHERE schemaname != 'pg_catalog'\n",
    "AND schemaname != 'information_schema'\n",
    "\"\"\")\n",
    "tables = cur.fetchall()\n",
    "print(len(tables))\n",
    "for table in tables:\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3e8b550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Column(name='date', type_code=25),\n",
       " Column(name='store_nbr', type_code=25),\n",
       " Column(name='lylty_card_nbr', type_code=25),\n",
       " Column(name='txn_id', type_code=25),\n",
       " Column(name='prod_nbr', type_code=25),\n",
       " Column(name='prod_name', type_code=25),\n",
       " Column(name='prod_qty', type_code=25),\n",
       " Column(name='tot_sales', type_code=25))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describing the tables\n",
    "cur.execute(\"\"\"\n",
    "SELECT * \n",
    "FROM store.transaction_tb\n",
    "LIMIT 0\n",
    "\"\"\")\n",
    "cur.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c851df4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n"
     ]
    }
   ],
   "source": [
    "# to determine the data type represented by id 25\n",
    "cur.execute(\"\"\"\n",
    "SELECT typname FROM pg_catalog.pg_type\n",
    "WHERE oid = 25\n",
    "\"\"\")\n",
    "id_25 = cur.fetchone()[0]\n",
    "print(id_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2a90e167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Kettle 135g Swt Pot Sea Salt',)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"\"\"\n",
    "SELECT prod_name \n",
    "FROM store.transaction_tb\n",
    "WHERE prod_name NOT LIKE '%g' \n",
    "AND prod_name NOT LIKE '%G'\n",
    "GROUP BY 1\n",
    "\"\"\")\n",
    "result = cur.fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "89bf1d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Burger Rings  220g',), ('CCs Nacho Cheese     175g',), ('CCs Original  175g',), ('CCs Tasty Cheese     175g',), ('Cheetos Chs & Bacon Balls  190g',), ('Cheetos Puffs  165g',), ('Cheezels Cheese  330g',), ('Cheezels Cheese Box  125g',), ('Cobs Popd Sea Salt  Chips  110g',), ('Cobs Popd Sour Crm  &Chives Chips  110g',), ('Cobs Popd Swt/Chlli &Sr/Cream Chips  110g',), ('Dorito Corn Chp     Supreme  380g',), ('Doritos Cheese      Supreme  330g',), ('Doritos Corn Chip Mexican Jalapeno  150g',), ('Doritos Corn Chip Southern Chicken  150g',), ('Doritos Corn Chips  Cheese Supreme  170g',), ('Doritos Corn Chips  Nacho Cheese  170g',), ('Doritos Corn Chips  Original  170g',), ('Doritos Mexicana     170g',), ('Doritos Salsa       Medium  300g',), ('Doritos Salsa Mild   300g',), ('French Fries Potato Chips  175g',), ('Grain Waves         Sweet Chilli  210g',), ('Grain Waves Sour    Cream&Chives  210G',), ('GrnWves Plus Btroot & Chilli Jam  180g',), ('Infuzions BBQ Rib   Prawn Crackers  110g',), ('Infuzions Mango     Chutny Papadums  70g',), ('Infuzions SourCream&Herbs Veg Strws  110g',), ('Infuzions Thai SweetChili PotatoMix  110g',), ('Infzns Crn Crnchers Tangy Gcamole  110g',), ('Kettle  135g Swt Pot Sea Salt',), ('Kettle Chilli  175g',), ('Kettle Honey Soy    Chicken  175g',), ('Kettle Mozzarella   Basil & Pesto  175g',), ('Kettle Original  175g',), ('Kettle Sea Salt     And Vinegar  175g',), ('Kettle Sensations   BBQ&Maple  150g',), ('Kettle Sensations   Camembert & Fig  150g',), ('Kettle Sensations   Siracha Lime  150g',), ('Kettle Sweet Chilli And Sour Cream  175g',), ('Kettle Tortilla ChpsBtroot&Ricotta  150g',), ('Kettle Tortilla ChpsFeta&Garlic  150g',), ('Kettle Tortilla ChpsHny&Jlpno Chili  150g',), ('Natural Chip        Compny SeaSalt 175g',), ('Natural Chip Co     Tmato Hrb&Spce  175g',), ('Natural ChipCo      Hony Soy Chckn 175g',), ('Natural ChipCo Sea  Salt & Vinegr  175g',), ('NCC Sour Cream &    Garden Chives  175g',), ('Old El Paso Salsa   Dip Chnky Tom Ht 300g',), ('Old El Paso Salsa   Dip Tomato Med  300g',), ('Old El Paso Salsa   Dip Tomato Mild  300g',), ('Pringles Barbeque    134g',), ('Pringles Chicken    Salt Crips  134g',), ('Pringles Mystery    Flavour  134g',), ('Pringles Original   Crisps  134g',), ('Pringles Slt Vingar  134g',), ('Pringles SourCream  Onion  134g',), ('Pringles Sthrn FriedChicken  134g',), ('Pringles Sweet&Spcy BBQ  134g',), ('Red Rock Deli Chikn&Garlic Aioli  150g',), ('Red Rock Deli Sp    Salt & Truffle  150G',), ('Red Rock Deli SR    Salsa & Mzzrlla  150g',), ('Red Rock Deli Thai  Chilli&Lime  150g',), ('RRD Chilli&         Coconut  150g',), ('RRD Honey Soy       Chicken  165g',), ('RRD Lime & Pepper    165g',), ('RRD Pc Sea Salt      165g',), ('RRD Salt & Vinegar   165g',), ('RRD SR Slow Rst     Pork Belly  150g',), ('RRD Steak &         Chimuchurri  150g',), ('RRD Sweet Chilli &  Sour Cream  165g',), ('Smith Crinkle Cut   Bolognese  150g',), ('Smith Crinkle Cut   Mac N Cheese  150g',), ('Smiths Chip Thinly  Cut Original  175g',), ('Smiths Chip Thinly  CutSalt/Vinegr 175g',), ('Smiths Chip Thinly  S/Cream&Onion  175g',), ('Smiths Crinkle      Original  330g',), ('Smiths Crinkle Chips Salt & Vinegar  330g',), ('Smiths Crinkle Cut  Chips Barbecue  170g',), ('Smiths Crinkle Cut  Chips Chicken  170g',), ('Smiths Crinkle Cut  Chips Chs&Onion 170g',), ('Smiths Crinkle Cut  Chips Original  170g',), ('Smiths Crinkle Cut  French OnionDip  150g',), ('Smiths Crinkle Cut  Salt & Vinegar  170g',), ('Smiths Crinkle Cut  Snag&Sauce  150g',), ('Smiths Crinkle Cut  Tomato Salsa  150g',), ('Smiths Crnkle Chip  Orgnl Big Bag  380g',), ('Smiths Thinly       Swt Chli&S/Cream 175G',), ('Smiths Thinly Cut   Roast Chicken  175g',), ('Snbts Whlgrn Crisps Cheddr&Mstrd  90g',), ('Sunbites Whlegrn    Crisps Frch/Onin  90g',), ('Thins Chips         Originl saltd  175g',), ('Thins Chips Light&  Tangy  175g',), ('Thins Chips Salt &  Vinegar  175g',), ('Thins Chips Seasonedchicken  175g',), ('Thins Potato Chips  Hot & Spicy  175g',), ('Tostitos Lightly    Salted  175g',), ('Tostitos Smoked     Chipotle  175g',), ('Tostitos Splash Of  Lime  175g',), ('Twisties Cheese      270g',), ('Twisties Cheese     Burger  250g',), ('Twisties Chicken 270g',), ('Tyrrells Crisps     Ched & Chives  165g',), ('Tyrrells Crisps     Lightly Salted  165g',), ('Woolworths Cheese   Rings  190g',), ('Woolworths Medium   Salsa  300g',), ('Woolworths Mild     Salsa  300g',), ('WW Crinkle Cut      Chicken  175g',), ('WW Crinkle Cut      Original  175g',), ('WW D/Style Chip     Sea Salt  200g',), ('WW Original Corn    Chips  200g',), ('WW Original Stacked Chips  160g',), ('WW Sour Cream &OnionStacked Chips  160g',), ('WW Supreme Cheese   Corn Chips  200g',)]\n"
     ]
    }
   ],
   "source": [
    "# cur.execute(\"\"\"\n",
    "# SELECT \n",
    "#         CONCAT_WS(' ',\n",
    "#                 SUBSTRING(PROD_NAME FROM '^[^0-9]+'),\n",
    "#                 SUBSTRING(PROD_NAME FROM '[0-9]+[a-zA-Z ]*$')\n",
    "# )\n",
    "# FROM store.transaction_tb\n",
    "# GROUP BY 1\n",
    "# \"\"\")\n",
    "# res = cur.fetchall()\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ae8889dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our column are of data so there is need to change their datatypes\n",
    "# check how many common phrases there are in prod_name\n",
    "# with open('transaction1.csv','r') as f:\n",
    "#     next(f)\n",
    "#     reader = csv.reader(f)\n",
    "#     unique_words_in_prod_name = set()\n",
    "#     for row in reader:\n",
    "#         prod_name = row[-3]\n",
    "#         unique_words_in_prod_name.add(prod_name)\n",
    "#     len_words = []\n",
    "#     for s in unique_words_in_prod_name:\n",
    "#         len_words.append(len(s))\n",
    "#     print(max(len_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a8e0a8",
   "metadata": {},
   "source": [
    "1. Datatypes are not right.\n",
    "2. Only one entry has data not like %g or %G\n",
    "3. Need to change %G to %g \n",
    "4. Separate product name from quantity of the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eae562",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

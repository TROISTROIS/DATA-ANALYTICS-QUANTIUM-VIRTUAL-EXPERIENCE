{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88010514",
   "metadata": {},
   "source": [
    "# GOAL : \n",
    "## FIND THE TYPE OF CUSTOMERS WHO PURCHASE CHIPS AND THEIR PURCHASING BEHAVIOUR WITHIN THE REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e5ae53",
   "metadata": {},
   "source": [
    "# PART ONE\n",
    "\n",
    "## Examine Transaction Data\n",
    "1. Look for inconsistencies, missing data across the dataset, outliers, correctly identified category items, numeric data across all tables.\n",
    "2. In case of identified anomalies, make necessary changes to the dataset and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f852b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import chardet\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc95f5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ascii\n"
     ]
    }
   ],
   "source": [
    "# encoding used in the file\n",
    "with open (\"QVI_transaction_data.csv\", mode='rb') as file:\n",
    "    raw_bytes = file.read(5)\n",
    "    detected_encoding = chardet.detect(raw_bytes)['encoding']\n",
    "    print(detected_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "902aa182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DATE', 'STORE_NBR', 'LYLTY_CARD_NBR', 'TXN_ID', 'PROD_NBR', 'PROD_NAME', 'PROD_QTY', 'TOT_SALES'], ['43390', '1', '1000', '1', '5', 'Natural Chip        Compny SeaSalt175g', '2', '6'], ['43599', '1', '1307', '348', '66', 'CCs Nacho Cheese    175g', '3', '6.3'], ['43605', '1', '1343', '383', '61', 'Smiths Crinkle Cut  Chips Chicken 170g', '2', '2.9'], ['43329', '2', '2373', '974', '69', 'Smiths Chip Thinly  S/Cream&Onion 175g', '5', '15'], ['43330', '2', '2426', '1038', '108', 'Kettle Tortilla ChpsHny&Jlpno Chili 150g', '3', '13.8'], ['43604', '4', '4074', '2982', '57', 'Old El Paso Salsa   Dip Tomato Mild 300g', '1', '5.1'], ['43601', '4', '4149', '3333', '16', 'Smiths Crinkle Chips Salt & Vinegar 330g', '1', '5.7'], ['43601', '4', '4196', '3539', '24', 'Grain Waves         Sweet Chilli 210g', '1', '3.6'], ['43332', '5', '5026', '4525', '42', 'Doritos Corn Chip Mexican Jalapeno 150g', '1', '3.9']]\n"
     ]
    }
   ],
   "source": [
    "# convert from ascii to utf-8\n",
    "with open(\"QVI_transaction_data.csv\", encoding='utf-8') as file:\n",
    "    rows = list(csv.reader(file))\n",
    "    header = rows[0]\n",
    "    print(rows[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a466f449",
   "metadata": {},
   "source": [
    "# INSIGHTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1a7aca",
   "metadata": {},
   "source": [
    "1. **ASCII** encoding is used in the csv file.\n",
    "2. The Date Column doers not look like a date.\n",
    "3. Numbers are represented as strings. \n",
    "4. Format headers to have the correct spelling and start with uppercase only.\n",
    "5. Separate quantity from product name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b43695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the dataset\n",
    "def explore_dataset(dataset,start,end,rows_columns=False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print(\"\\n\")\n",
    "    if rows_columns:\n",
    "        print(\"There are {} rows\".format(len(dataset)))\n",
    "        print(\"There are {} columns\".format(len(dataset[0])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "509dbfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DATE', 'STORE_NBR', 'LYLTY_CARD_NBR', 'TXN_ID', 'PROD_NBR', 'PROD_NAME', 'PROD_QTY', 'TOT_SALES']\n",
      "\n",
      "\n",
      "['43390', '1', '1000', '1', '5', 'Natural Chip        Compny SeaSalt175g', '2', '6']\n",
      "\n",
      "\n",
      "['43599', '1', '1307', '348', '66', 'CCs Nacho Cheese    175g', '3', '6.3']\n",
      "\n",
      "\n",
      "['43605', '1', '1343', '383', '61', 'Smiths Crinkle Cut  Chips Chicken 170g', '2', '2.9']\n",
      "\n",
      "\n",
      "['43329', '2', '2373', '974', '69', 'Smiths Chip Thinly  S/Cream&Onion 175g', '5', '15']\n",
      "\n",
      "\n",
      "['43330', '2', '2426', '1038', '108', 'Kettle Tortilla ChpsHny&Jlpno Chili 150g', '3', '13.8']\n",
      "\n",
      "\n",
      "['43604', '4', '4074', '2982', '57', 'Old El Paso Salsa   Dip Tomato Mild 300g', '1', '5.1']\n",
      "\n",
      "\n",
      "['43601', '4', '4149', '3333', '16', 'Smiths Crinkle Chips Salt & Vinegar 330g', '1', '5.7']\n",
      "\n",
      "\n",
      "['43601', '4', '4196', '3539', '24', 'Grain Waves         Sweet Chilli 210g', '1', '3.6']\n",
      "\n",
      "\n",
      "['43332', '5', '5026', '4525', '42', 'Doritos Corn Chip Mexican Jalapeno 150g', '1', '3.9']\n",
      "\n",
      "\n",
      "There are 264837 rows\n",
      "There are 8 columns\n"
     ]
    }
   ],
   "source": [
    "explore_dataset(rows,0,10,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3dd8ccd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DATE', 'STORE_NBR', 'LYLTY_CARD_NBR', 'TXN_ID', 'PROD_NBR', 'PROD_NAME', 'PROD_QTY', 'TOT_SALES']\n",
      "\n",
      "\n",
      "['43390', '1', '1000', '1', '5', 'Natural Chip        Compny SeaSalt175g', '2', '6']\n",
      "\n",
      "\n",
      "['43599', '1', '1307', '348', '66', 'CCs Nacho Cheese    175g', '3', '6.3']\n",
      "\n",
      "\n",
      "['43605', '1', '1343', '383', '61', 'Smiths Crinkle Cut  Chips Chicken 170g', '2', '2.9']\n",
      "\n",
      "\n",
      "['43329', '2', '2373', '974', '69', 'Smiths Chip Thinly  S/Cream&Onion 175g', '5', '15']\n",
      "\n",
      "\n",
      "There are 264837 rows\n",
      "There are 8 columns\n"
     ]
    }
   ],
   "source": [
    "# check if there are empty sublists in our list\n",
    "rows =  [sublist for sublist in rows if sublist]\n",
    "explore_dataset(rows,0,5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9957ac40-23b2-4667-9e41-ad33b98f12f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1709 duplicate entries\n",
      "There are 263128 unique entries\n",
      "[['43605', '55', '55073', '48887', '113', 'Twisties Chicken270g', '1', '4.6'], ['43475', '7', '7364', '7739', '20', 'Doritos Cheese      Supreme 330g', '2', '11.4'], ['43391', '12', '12301', '10982', '93', 'Doritos Corn Chip Southern Chicken 150g', '2', '7.8'], ['43351', '16', '16427', '14546', '81', 'Pringles Original   Crisps 134g', '1', '3.7'], ['43315', '19', '19272', '16683', '31', 'Infzns Crn Crnchers Tangy Gcamole 110g', '2', '7.6'], ['43401', '47', '47204', '42616', '45', 'Smiths Thinly Cut   Roast Chicken 175g', '2', '6'], ['43609', '48', '48179', '44177', '56', 'Cheezels Cheese Box 125g', '2', '4.2'], ['43559', '55', '55036', '48663', '91', 'CCs Tasty Cheese    175g', '2', '4.2'], ['43282', '55', '55073', '48884', '91', 'CCs Tasty Cheese    175g', '2', '4.2'], ['43489', '58', '58121', '53351', '42', 'Doritos Corn Chip Mexican Jalapeno 150g', '2', '7.8']]\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates\n",
    "duplicate_entries = []\n",
    "unique_entries = set()\n",
    "rows_with_duplicates = []\n",
    "for row in rows:\n",
    "    transaction_id = row[3]\n",
    "    if transaction_id not in unique_entries:\n",
    "        unique_entries.add(transaction_id)\n",
    "    else:\n",
    "        duplicate_entries.append(transaction_id)\n",
    "        rows_with_duplicates.append(row)\n",
    "print(\"There are {} duplicate entries\".format(len(duplicate_entries)))\n",
    "print(\"There are {} unique entries\".format(len(unique_entries)))\n",
    "print(rows_with_duplicates[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5f3142",
   "metadata": {},
   "source": [
    "Out of these duplicate entries, they have similar transaction ids, loyalty card numbers but different products. so we will leave them as they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f10cea29-0e41-49d4-ab9d-ec60f20c717d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DATE': 0, 'STORE_NBR': 1, 'LYLTY_CARD_NBR': 2, 'TXN_ID': 3, 'PROD_NBR': 4, 'PROD_NAME': 5, 'PROD_QTY': 6, 'TOT_SALES': 7}\n"
     ]
    }
   ],
   "source": [
    "# get the index of every column\n",
    "col_index = {}\n",
    "for i in range(len(header)):\n",
    "    col_index[header[i]] = i\n",
    "print(col_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f861ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openpyxl import load_workbook\n",
    "# from datetime import datetime, timedelta\n",
    "\n",
    "# def excel_serial_date_to_datetime(serial_date):\n",
    "#     base_date = datetime(1899, 12, 31)\n",
    "#     delta = timedelta(days=serial_date)\n",
    "#     resulting_date = base_date + delta\n",
    "#     return resulting_date\n",
    "\n",
    "# # Example usage\n",
    "# excel_file_path = 'C:/Users/user/I am learning ML/Quantium VIrtual Experience/Data Preparation and Customer Analysis/QVI_transaction_data.xlsx'\n",
    "# sheet_name = 'in'\n",
    "# date_column_index = 0  # Adjust the column index to match the column containing Excel serial dates\n",
    "\n",
    "# # Load the Excel file\n",
    "# workbook = load_workbook(excel_file_path)\n",
    "\n",
    "# # Select the desired sheet\n",
    "# sheet = workbook[sheet_name]\n",
    "\n",
    "# # Iterate over the rows and convert Excel serial dates to datetime objects\n",
    "# for row in sheet.iter_rows(min_row=2, values_only=True):  # Assuming the first row is a header\n",
    "#     serial_date = row[date_column_index]\n",
    "#     date = list(excel_serial_date_to_datetime(serial_date).date)\n",
    "#     print(date[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9803985-316d-4dec-a8e0-5868c782a2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2018, 10, 18, 0, 0), datetime.datetime(2019, 5, 15, 0, 0), datetime.datetime(2019, 5, 21, 0, 0), datetime.datetime(2018, 8, 18, 0, 0), datetime.datetime(2018, 8, 19, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "def excel_serial_date_to_datetime(serial_date):\n",
    "    base_date = datetime(1899, 12, 31)\n",
    "    delta = timedelta(days=float(serial_date))\n",
    "    resulting_date = base_date + delta\n",
    "    return resulting_date\n",
    "\n",
    "def serialdate_to_datetime(rows, idx):\n",
    "    converted_dates = []\n",
    "    for i, row in enumerate(rows):\n",
    "        if i == 0:\n",
    "            continue  # Skip header if present\n",
    "        serial_date = row[idx]\n",
    "        date = excel_serial_date_to_datetime(serial_date)\n",
    "        converted_dates.append(date)\n",
    "    return converted_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6fc9284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2018, 10, 18, 0, 0), datetime.datetime(2019, 5, 15, 0, 0), datetime.datetime(2019, 5, 21, 0, 0), datetime.datetime(2018, 8, 18, 0, 0), datetime.datetime(2018, 8, 19, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "dates = serialdate_to_datetime(rows, date_column_index)\n",
    "print(dates[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6c266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88010514",
   "metadata": {},
   "source": [
    "# GOAL : \n",
    "## FIND THE TYPE OF CUSTOMERS WHO PURCHASE CHIPS AND THEIR PURCHASING BEHAVIOUR WITHIN THE REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e5ae53",
   "metadata": {},
   "source": [
    "# PART ONE\n",
    "\n",
    "## Examine Transaction Data\n",
    "1. Look for inconsistencies, missing data across the dataset, outliers, correctly identified category items, numeric data across all tables.\n",
    "2. In case of identified anomalies, make necessary changes to the dataset and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2f852b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import chardet\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fc95f5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ascii\n"
     ]
    }
   ],
   "source": [
    "# encoding used in the file\n",
    "with open (\"QVI_transaction_data.csv\", mode='rb') as file:\n",
    "    raw_bytes = file.read(5)\n",
    "    detected_encoding = chardet.detect(raw_bytes)['encoding']\n",
    "    print(detected_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "902aa182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DATE', 'STORE_NBR', 'LYLTY_CARD_NBR', 'TXN_ID', 'PROD_NBR', 'PROD_NAME', 'PROD_QTY', 'TOT_SALES'], ['43390', '1', '1000', '1', '5', 'Natural Chip        Compny SeaSalt175g', '2', '6'], ['43599', '1', '1307', '348', '66', 'CCs Nacho Cheese    175g', '3', '6.3'], ['43605', '1', '1343', '383', '61', 'Smiths Crinkle Cut  Chips Chicken 170g', '2', '2.9'], ['43329', '2', '2373', '974', '69', 'Smiths Chip Thinly  S/Cream&Onion 175g', '5', '15'], ['43330', '2', '2426', '1038', '108', 'Kettle Tortilla ChpsHny&Jlpno Chili 150g', '3', '13.8'], ['43604', '4', '4074', '2982', '57', 'Old El Paso Salsa   Dip Tomato Mild 300g', '1', '5.1'], ['43601', '4', '4149', '3333', '16', 'Smiths Crinkle Chips Salt & Vinegar 330g', '1', '5.7'], ['43601', '4', '4196', '3539', '24', 'Grain Waves         Sweet Chilli 210g', '1', '3.6'], ['43332', '5', '5026', '4525', '42', 'Doritos Corn Chip Mexican Jalapeno 150g', '1', '3.9']]\n"
     ]
    }
   ],
   "source": [
    "# convert from ascii to utf-8\n",
    "with open(\"QVI_transaction_data.csv\", encoding='utf-8') as file:\n",
    "    rows = list(csv.reader(file))\n",
    "    header = rows[0]\n",
    "    print(rows[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a466f449",
   "metadata": {},
   "source": [
    "# INSIGHTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1a7aca",
   "metadata": {},
   "source": [
    "1. **ASCII** encoding is used in the csv file.\n",
    "2. The Date Column doers not look like a date.\n",
    "3. Numbers are represented as strings. \n",
    "4. Format headers to have the correct spelling and start with uppercase only.\n",
    "5. Separate quantity from product name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0b43695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the dataset\n",
    "def explore_dataset(dataset,start,end,rows_columns=False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print(\"\\n\")\n",
    "    if rows_columns:\n",
    "        print(\"There are {} rows\".format(len(dataset)))\n",
    "        print(\"There are {} columns\".format(len(dataset[0])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "509dbfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DATE', 'STORE_NBR', 'LYLTY_CARD_NBR', 'TXN_ID', 'PROD_NBR', 'PROD_NAME', 'PROD_QTY', 'TOT_SALES']\n",
      "\n",
      "\n",
      "['43390', '1', '1000', '1', '5', 'Natural Chip        Compny SeaSalt175g', '2', '6']\n",
      "\n",
      "\n",
      "['43599', '1', '1307', '348', '66', 'CCs Nacho Cheese    175g', '3', '6.3']\n",
      "\n",
      "\n",
      "['43605', '1', '1343', '383', '61', 'Smiths Crinkle Cut  Chips Chicken 170g', '2', '2.9']\n",
      "\n",
      "\n",
      "['43329', '2', '2373', '974', '69', 'Smiths Chip Thinly  S/Cream&Onion 175g', '5', '15']\n",
      "\n",
      "\n",
      "['43330', '2', '2426', '1038', '108', 'Kettle Tortilla ChpsHny&Jlpno Chili 150g', '3', '13.8']\n",
      "\n",
      "\n",
      "['43604', '4', '4074', '2982', '57', 'Old El Paso Salsa   Dip Tomato Mild 300g', '1', '5.1']\n",
      "\n",
      "\n",
      "['43601', '4', '4149', '3333', '16', 'Smiths Crinkle Chips Salt & Vinegar 330g', '1', '5.7']\n",
      "\n",
      "\n",
      "['43601', '4', '4196', '3539', '24', 'Grain Waves         Sweet Chilli 210g', '1', '3.6']\n",
      "\n",
      "\n",
      "['43332', '5', '5026', '4525', '42', 'Doritos Corn Chip Mexican Jalapeno 150g', '1', '3.9']\n",
      "\n",
      "\n",
      "There are 264837 rows\n",
      "There are 8 columns\n"
     ]
    }
   ],
   "source": [
    "explore_dataset(rows,0,10,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3dd8ccd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DATE', 'STORE_NBR', 'LYLTY_CARD_NBR', 'TXN_ID', 'PROD_NBR', 'PROD_NAME', 'PROD_QTY', 'TOT_SALES']\n",
      "\n",
      "\n",
      "['43390', '1', '1000', '1', '5', 'Natural Chip        Compny SeaSalt175g', '2', '6']\n",
      "\n",
      "\n",
      "['43599', '1', '1307', '348', '66', 'CCs Nacho Cheese    175g', '3', '6.3']\n",
      "\n",
      "\n",
      "['43605', '1', '1343', '383', '61', 'Smiths Crinkle Cut  Chips Chicken 170g', '2', '2.9']\n",
      "\n",
      "\n",
      "['43329', '2', '2373', '974', '69', 'Smiths Chip Thinly  S/Cream&Onion 175g', '5', '15']\n",
      "\n",
      "\n",
      "There are 264837 rows\n",
      "There are 8 columns\n"
     ]
    }
   ],
   "source": [
    "# check if there are empty sublists in our list\n",
    "rows =  [sublist for sublist in rows if sublist]\n",
    "explore_dataset(rows,0,5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9957ac40-23b2-4667-9e41-ad33b98f12f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1709 duplicate entries\n",
      "There are 263128 unique entries\n",
      "[['43605', '55', '55073', '48887', '113', 'Twisties Chicken270g', '1', '4.6'], ['43475', '7', '7364', '7739', '20', 'Doritos Cheese      Supreme 330g', '2', '11.4'], ['43391', '12', '12301', '10982', '93', 'Doritos Corn Chip Southern Chicken 150g', '2', '7.8'], ['43351', '16', '16427', '14546', '81', 'Pringles Original   Crisps 134g', '1', '3.7'], ['43315', '19', '19272', '16683', '31', 'Infzns Crn Crnchers Tangy Gcamole 110g', '2', '7.6'], ['43401', '47', '47204', '42616', '45', 'Smiths Thinly Cut   Roast Chicken 175g', '2', '6'], ['43609', '48', '48179', '44177', '56', 'Cheezels Cheese Box 125g', '2', '4.2'], ['43559', '55', '55036', '48663', '91', 'CCs Tasty Cheese    175g', '2', '4.2'], ['43282', '55', '55073', '48884', '91', 'CCs Tasty Cheese    175g', '2', '4.2'], ['43489', '58', '58121', '53351', '42', 'Doritos Corn Chip Mexican Jalapeno 150g', '2', '7.8']]\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates\n",
    "duplicate_entries = []\n",
    "unique_entries = set()\n",
    "rows_with_duplicates = []\n",
    "for row in rows:\n",
    "    transaction_id = row[3]\n",
    "    if transaction_id not in unique_entries:\n",
    "        unique_entries.add(transaction_id)\n",
    "    else:\n",
    "        duplicate_entries.append(transaction_id)\n",
    "        rows_with_duplicates.append(row)\n",
    "print(\"There are {} duplicate entries\".format(len(duplicate_entries)))\n",
    "print(\"There are {} unique entries\".format(len(unique_entries)))\n",
    "print(rows_with_duplicates[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5f3142",
   "metadata": {},
   "source": [
    "Out of these duplicate entries, they have similar transaction ids, loyalty card numbers but different products. so we will leave them as they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f10cea29-0e41-49d4-ab9d-ec60f20c717d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DATE': 0, 'STORE_NBR': 1, 'LYLTY_CARD_NBR': 2, 'TXN_ID': 3, 'PROD_NBR': 4, 'PROD_NAME': 5, 'PROD_QTY': 6, 'TOT_SALES': 7}\n"
     ]
    }
   ],
   "source": [
    "# get the index of every column\n",
    "col_index = {}\n",
    "for i in range(len(header)):\n",
    "    col_index[header[i]] = i\n",
    "print(col_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e9803985-316d-4dec-a8e0-5868c782a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def excel_serial_date_to_datetime(serial_date):\n",
    "    base_date = datetime(1899, 12, 31)\n",
    "    delta = timedelta(days=float(serial_date))\n",
    "    resulting_date = base_date + delta\n",
    "    return resulting_date\n",
    "\n",
    "def serialdate_to_datetime(rows, idx):\n",
    "    for i, row in enumerate(rows):\n",
    "        if i == 0:\n",
    "            continue  # Skip header if present\n",
    "        serial_date = row[idx]\n",
    "        date = excel_serial_date_to_datetime(serial_date)\n",
    "        row[idx] = date\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7dff3605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DATE', 'STORE_NBR', 'LYLTY_CARD_NBR', 'TXN_ID', 'PROD_NBR', 'PROD_NAME', 'PROD_QTY', 'TOT_SALES'], [datetime.datetime(2018, 10, 18, 0, 0), '1', '1000', '1', '5', 'Natural Chip        Compny SeaSalt175g', '2', '6'], [datetime.datetime(2019, 5, 15, 0, 0), '1', '1307', '348', '66', 'CCs Nacho Cheese    175g', '3', '6.3'], [datetime.datetime(2019, 5, 21, 0, 0), '1', '1343', '383', '61', 'Smiths Crinkle Cut  Chips Chicken 170g', '2', '2.9'], [datetime.datetime(2018, 8, 18, 0, 0), '2', '2373', '974', '69', 'Smiths Chip Thinly  S/Cream&Onion 175g', '5', '15']]\n"
     ]
    }
   ],
   "source": [
    "rows = serialdate_to_datetime(rows, date_column_index)\n",
    "print(rows[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "49aab09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DATE', 'STORE_NBR', 'LYLTY_CARD_NBR', 'TXN_ID', 'PROD_NBR', 'PROD_NAME', 'PROD_QTY', 'TOT_SALES'], [datetime.datetime(2018, 10, 18, 0, 0), '1', '1000', '1', '5', 'Natural Chip        Compny SeaSalt175g', '2', '6'], [datetime.datetime(2019, 5, 15, 0, 0), '1', '1307', '348', '66', 'CCs Nacho Cheese    175g', '3', '6.3'], [datetime.datetime(2019, 5, 21, 0, 0), '1', '1343', '383', '61', 'Smiths Crinkle Cut  Chips Chicken 170g', '2', '2.9'], [datetime.datetime(2018, 8, 18, 0, 0), '2', '2373', '974', '69', 'Smiths Chip Thinly  S/Cream&Onion 175g', '5', '15']]\n"
     ]
    }
   ],
   "source": [
    "print(rows[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb3496",
   "metadata": {},
   "source": [
    "I will write to the csv file later, to keep permanent changes of the date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fcfa14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the data types match\n",
    "def check_datatypes(rows,header):    \n",
    "    # Initialize a dictionary to store the data types for each column\n",
    "    column_data_types = {col: None for col in header}\n",
    "\n",
    "    # Iterate over each row of the CSV file\n",
    "    for row in rows:\n",
    "        # Iterate over each column in the row\n",
    "        for i, col_value in enumerate(row):\n",
    "            # Check if the data type for the column has been set yet\n",
    "            if not column_data_types[header[i]]:\n",
    "                # If not, set the data type to the type of the current value\n",
    "                column_data_types[header[i]] = type(col_value)\n",
    "            else:\n",
    "                # If it has been set, check if the current value has a different data type\n",
    "                if column_data_types[header[i]] != type(col_value):\n",
    "                    # If it does, set the data type to a generic \"object\" type\n",
    "                    column_data_types[header[i]] = object\n",
    "\n",
    "    # Print the data types for each column\n",
    "    for col, data_type in column_data_types.items():\n",
    "        print(f\"{col}: {data_type.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e4fccf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE: object\n",
      "STORE_NBR: str\n",
      "LYLTY_CARD_NBR: str\n",
      "TXN_ID: str\n",
      "PROD_NBR: str\n",
      "PROD_NAME: str\n",
      "PROD_QTY: str\n",
      "TOT_SALES: str\n"
     ]
    }
   ],
   "source": [
    "check_datatypes(rows,header)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0e6873",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88010514",
   "metadata": {},
   "source": [
    "# GOAL : \n",
    "## FIND THE TYPE OF CUSTOMERS WHO PURCHASE CHIPS AND THEIR PURCHASING BEHAVIOUR WITHIN THE REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e5ae53",
   "metadata": {},
   "source": [
    "# PART ONE\n",
    "\n",
    "## Examine Transaction Data\n",
    "1. Look for inconsistencies, missing data across the dataset, outliers, correctly identified category items, numeric data across all tables.\n",
    "2. In case of identified anomalies, make necessary changes to the dataset and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2f852b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import chardet\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fc95f5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ascii\n"
     ]
    }
   ],
   "source": [
    "# encoding used in the file\n",
    "with open (\"QVI_transaction_data.csv\", mode='rb') as file:\n",
    "    raw_bytes = file.read(5)\n",
    "    detected_encoding = chardet.detect(raw_bytes)['encoding']\n",
    "    print(detected_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902aa182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from ascii to utf-8\n",
    "with open(\"QVI_transaction_data.csv\", encoding='utf-8') as file:\n",
    "    rows = list(csv.reader(file))\n",
    "    header = rows[0]\n",
    "    print(rows[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a466f449",
   "metadata": {},
   "source": [
    "# INSIGHTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1a7aca",
   "metadata": {},
   "source": [
    "1. **ASCII** encoding is used in the csv file.\n",
    "2. The Date Column doers not look like a date.\n",
    "3. Numbers are represented as strings. \n",
    "4. Format headers to have the correct spelling and start with uppercase only.\n",
    "5. Separate quantity from product name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b43695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the dataset\n",
    "def explore_dataset(dataset,start,end,rows_columns=False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print(\"\\n\")\n",
    "    if rows_columns:\n",
    "        print(\"There are {} rows\".format(len(dataset)))\n",
    "        print(\"There are {} columns\".format(len(dataset[0])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509dbfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_dataset(rows,0,10,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd8ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are empty sublists in our list\n",
    "empty_rows =  [sublist for sublist in rows if sublist]\n",
    "explore_dataset(empty_rows,0,5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9957ac40-23b2-4667-9e41-ad33b98f12f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates based on key columns\n",
    "duplicate_entries = []\n",
    "seen = set()\n",
    "\n",
    "for row in rows:\n",
    "#     use a tuple as a key\n",
    "    key = tuple(row)\n",
    "    if key in seen:\n",
    "        duplicate_entries.append(row)\n",
    "    else:\n",
    "        seen.add(key)\n",
    "# duplicate entries\n",
    "duplicates = []\n",
    "for duplicate in duplicate_entries:\n",
    "    duplicates.append(duplicate)\n",
    "    print(duplicates)\n",
    "print(\"There are {} duplicate entries\".format(len(duplicates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72649096",
   "metadata": {},
   "source": [
    "1 duplicate entry to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10cea29-0e41-49d4-ab9d-ec60f20c717d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the index of every column\n",
    "col_index = {}\n",
    "for i in range(len(header)):\n",
    "    col_index[header[i]] = i\n",
    "print(col_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9803985-316d-4dec-a8e0-5868c782a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert excel date to python datetime object\n",
    "def excel_serial_date_to_datetime(serial_date):\n",
    "    base_date = datetime(1899, 12, 31)\n",
    "    delta = timedelta(days=float(serial_date))\n",
    "    resulting_date = base_date + delta\n",
    "    return resulting_date\n",
    "\n",
    "def serialdate_to_datetime(rows, idx):\n",
    "    for i, row in enumerate(rows):\n",
    "        if i == 0:\n",
    "            continue  # Skip header if present\n",
    "        serial_date = row[idx]\n",
    "        date = excel_serial_date_to_datetime(serial_date)\n",
    "        row[idx] = date\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dff3605",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = serialdate_to_datetime(rows, 0)\n",
    "print(rows[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb3496",
   "metadata": {},
   "source": [
    "I will write to the csv file later, to keep permanent changes of the date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfa14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the data types match\n",
    "def check_datatypes(rows,header):    \n",
    "    # Initialize a dictionary to store the data types for each column\n",
    "    column_data_types = {col: None for col in header}\n",
    "\n",
    "    # Iterate over each row of the CSV file\n",
    "    for row in rows:\n",
    "        # Iterate over each column in the row\n",
    "        for i, col_value in enumerate(row):\n",
    "            # Check if the data type for the column has been set yet\n",
    "            if not column_data_types[header[i]]:\n",
    "                # If not, set the data type to the type of the current value\n",
    "                column_data_types[header[i]] = type(col_value)\n",
    "            else:\n",
    "                # If it has been set, check if the current value has a different data type\n",
    "                if column_data_types[header[i]] != type(col_value):\n",
    "                    # If it does, set the data type to a generic \"object\" type\n",
    "                    column_data_types[header[i]] = object\n",
    "\n",
    "    # Print the data types for each column\n",
    "    for col, data_type in column_data_types.items():\n",
    "        print(f\"{col}: {data_type.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fccf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_datatypes(rows,header)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0e6873",
   "metadata": {},
   "source": [
    "Columns that should be integers are represented as strings:\n",
    "1. Store Number\n",
    "2. Loyalty Card Number\n",
    "3. Prod Number \n",
    "\n",
    "The Date Column will also be converted to a datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162915be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change Product Name column to just the product name and create another column for Quantity in grams.\n",
    "# PROD_NAME = []\n",
    "# PROD_QUANTITY = []\n",
    "\n",
    "# for row in rows:\n",
    "#     products = row[5]\n",
    "#     for product in products:\n",
    "# #     split the string into words\n",
    "#         split_product = product.rsplit(' ',1)\n",
    "#         PROD_NAME.append(split_product[0])\n",
    "#         PROD_QUANTITY.append(split_product[1])\n",
    "# for i in range(len(PROD_NAME)):\n",
    "#     print(f\"Product:{PROD_NAME[i]}, Quantity:{PROD_QUANTITY[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf72a4",
   "metadata": {},
   "source": [
    "We have created a new list of two separate columns that will be put in the csv file when writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5468c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to a new csv file\n",
    "with open('transaction1.csv', 'w',newline='', encoding='utf-8') as newfile:\n",
    "    writer = csv.writer(newfile)\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cf6b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from ascii to utf-8\n",
    "with open(\"transaction1.csv\", encoding='utf-8') as file:\n",
    "    rows = list(csv.reader(file))\n",
    "    header = rows[0]\n",
    "    print(rows[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b4f028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
